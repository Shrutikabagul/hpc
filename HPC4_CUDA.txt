#include <iostream>
#include <cuda.h>

using namespace std;

// --------------------------------------
// CUDA Kernel for Vector Addition
__global__ void vectorAdd(int* A, int* B, int* C, int n) {
    int i = threadIdx.x + blockIdx.x * blockDim.x;
    if (i < n)
        C[i] = A[i] + B[i];
}

// --------------------------------------
// CUDA Kernel for Matrix Multiplication
__global__ void matrixMul(int* A, int* B, int* C, int N) {
    int row = threadIdx.y + blockIdx.y * blockDim.y;
    int col = threadIdx.x + blockIdx.x * blockDim.x;

    if (row < N && col < N) {
        int sum = 0;
        for (int k = 0; k < N; ++k)
            sum += A[row * N + k] * B[k * N + col];
        C[row * N + col] = sum;
    }
}

// --------------------------------------
int main() {
    int n;
    cout << "Enter size of vectors (e.g. 1024): ";
    cin >> n;

    // Host memory allocation for vectors
    int* h_A = new int[n];
    int* h_B = new int[n];
    int* h_C = new int[n];

    // Initialize vectors
    for (int i = 0; i < n; i++) {
        h_A[i] = i;
        h_B[i] = 2 * i;
    }

    // Device memory allocation
    int *d_A, *d_B, *d_C;
    cudaMalloc(&d_A, n * sizeof(int));
    cudaMalloc(&d_B, n * sizeof(int));
    cudaMalloc(&d_C, n * sizeof(int));

    // Copy inputs to device
    cudaMemcpy(d_A, h_A, n * sizeof(int), cudaMemcpyHostToDevice);
    cudaMemcpy(d_B, h_B, n * sizeof(int), cudaMemcpyHostToDevice);

    // Launch vector addition kernel
    int blockSize = 256;
    int gridSize = (n + blockSize - 1) / blockSize;
    vectorAdd<<<gridSize, blockSize>>>(d_A, d_B, d_C, n);
    cudaDeviceSynchronize();

    // Copy result back to host
    cudaMemcpy(h_C, d_C, n * sizeof(int), cudaMemcpyDeviceToHost);

    cout << "\nVector Addition Result (first 10 values): ";
    for (int i = 0; i < min(10, n); i++) {
        cout << h_C[i] << " ";
    }

    // --------------------------------------
    // Matrix Multiplication

    int N;
    cout << "\n\nEnter size N for NxN matrices (e.g. 4): ";
    cin >> N;

    int size = N * N;
    int* h_M1 = new int[size];
    int* h_M2 = new int[size];
    int* h_M3 = new int[size];

    // Initialize matrices
    for (int i = 0; i < size; i++) {
        h_M1[i] = i + 1;
        h_M2[i] = i + 1;
    }

    int *d_M1, *d_M2, *d_M3;
    cudaMalloc(&d_M1, size * sizeof(int));
    cudaMalloc(&d_M2, size * sizeof(int));
    cudaMalloc(&d_M3, size * sizeof(int));

    cudaMemcpy(d_M1, h_M1, size * sizeof(int), cudaMemcpyHostToDevice);
    cudaMemcpy(d_M2, h_M2, size * sizeof(int), cudaMemcpyHostToDevice);

    dim3 threadsPerBlock(16, 16);
    dim3 blocksPerGrid((N + 15) / 16, (N + 15) / 16);

    matrixMul<<<blocksPerGrid, threadsPerBlock>>>(d_M1, d_M2, d_M3, N);
    cudaDeviceSynchronize();

    cudaMemcpy(h_M3, d_M3, size * sizeof(int), cudaMemcpyDeviceToHost);

    cout << "\nMatrix Multiplication Result (first 4x4 block):\n";
    for (int i = 0; i < min(N, 4); i++) {
        for (int j = 0; j < min(N, 4); j++) {
            cout << h_M3[i * N + j] << "\t";
        }
        cout << endl;
    }

    // Free memory
    delete[] h_A; delete[] h_B; delete[] h_C;
    delete[] h_M1; delete[] h_M2; delete[] h_M3;
    cudaFree(d_A); cudaFree(d_B); cudaFree(d_C);
    cudaFree(d_M1); cudaFree(d_M2); cudaFree(d_M3);

    return 0;
}

//nvcc cuda_vector_matrix.cu -o cuda_program
//./cuda_program
//If you're using Visual Studio with CUDA Toolkit installed, create a .cu CUDA project and paste the code inside main.cu
//Enter size of vectors (e.g. 1024): 10
//Enter size N for NxN matrices (e.g. 4): 2
//Vector Addition Result (first 10 values): 0 3 6 9 12 15 18 21 24 27
//Matrix Multiplication Result (first 4x4 block):
//7	10
//15	22

